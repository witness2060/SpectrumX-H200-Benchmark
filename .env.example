# =====================================================
# SpectrumX H200 Benchmark - 環境変数設定ファイル
# =====================================================
# このファイルを .env にコピーして、必要な値を設定してください
# cp .env.example .env

# ====================
# 認証関連
# ====================
# Hugging Face トークン（Llama等のプライベートモデル使用時に必要）
# https://huggingface.co/settings/tokens から取得
HF_TOKEN=your-hugging-face-token-here

# Weights & Biases トークン（実験トラッキング用、オプション）
WANDB_API_KEY=your-wandb-api-key-here

# ====================
# ノード設定
# ====================
# カスタムノードリスト（カンマ区切り）
# 例: fukushimadc-02-hgx-0001,fukushimadc-02-hgx-0002
CUSTOM_NODES=

# マスターノードのIPアドレス（自動検出されるが、明示的に指定も可能）
MASTER_IP=

# ====================
# 実行設定
# ====================
# 確認プロンプトをスキップ（自動実行用）
SKIP_CONFIRM=false

# デフォルトのモデル名
DEFAULT_MODEL=meta-llama/Llama-2-7b-hf

# デフォルトのノード数
DEFAULT_NODES=2

# デフォルトのテストタイプ（nccl, pytorch, sft, full）
DEFAULT_TEST_TYPE=sft

# ====================
# データセット設定
# ====================
# カスタムデータセットのパス
CUSTOM_DATASET_PATH=

# データセットのサンプル数（デフォルト: 10000）
DATASET_NUM_SAMPLES=10000

# 最大シーケンス長（デフォルト: 2048）
MAX_SEQUENCE_LENGTH=2048

# ====================
# 学習設定
# ====================
# エポック数
NUM_EPOCHS=3

# バッチサイズ（GPU当たり）
BATCH_SIZE_PER_GPU=8

# 学習率
LEARNING_RATE=2e-4

# Gradient Accumulation Steps
GRADIENT_ACCUMULATION_STEPS=16

# ====================
# GPU/計算設定
# ====================
# 使用するGPU数（ノード当たり、デフォルト: 8）
GPUS_PER_NODE=8

# Mixed Precision設定（bf16, fp16, fp32）
PRECISION=bf16

# DeepSpeed設定ファイル（カスタム設定を使用する場合）
DEEPSPEED_CONFIG=

# ====================
# ネットワーク設定
# ====================
# NCCLデバッグレベル（WARN, INFO, DEBUG）
NCCL_DEBUG=WARN

# InfiniBandデバイス（デフォルト: mlx5_0,mlx5_1）
NCCL_IB_HCA=mlx5_0,mlx5_1

# ネットワークインターフェース
NCCL_SOCKET_IFNAME=bond0

# ====================
# ログ・出力設定
# ====================
# 結果出力ディレクトリ
RESULTS_DIR=results

# ログレベル（DEBUG, INFO, WARNING, ERROR）
LOG_LEVEL=INFO

# レポート先（wandb, tensorboard, none）
REPORT_TO=none

# ====================
# プロキシ設定（必要な場合）
# ====================
# HTTP_PROXY=http://proxy.example.com:8080
# HTTPS_PROXY=http://proxy.example.com:8080
# NO_PROXY=localhost,127.0.0.1,10.0.0.0/8

# ====================
# その他のオプション
# ====================
# Hugging Faceミラー（中国等でのアクセス高速化）
# HF_ENDPOINT=https://hf-mirror.com

# PyTorchのCUDAメモリ設定
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

# データローダーのワーカー数
DATALOADER_NUM_WORKERS=4