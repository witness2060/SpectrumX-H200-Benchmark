# SpectrumX + H200 Ã— 8ãƒãƒ¼ãƒ‰ç’°å¢ƒ
# æœ€é©åŒ–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œã‚¬ã‚¤ãƒ‰

## ğŸ“‹ ç›®æ¬¡

1. [æ¦‚è¦](#æ¦‚è¦)
2. [ç’°å¢ƒæ§‹ç¯‰](#ç’°å¢ƒæ§‹ç¯‰)
3. [ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ](#ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ)
4. [çµæœç¢ºèª](#çµæœç¢ºèª)
5. [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)

---

## æ¦‚è¦

æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€SpectrumX + H200 Ã— 8ãƒãƒ¼ãƒ‰ç’°å¢ƒã§ã€Llama-2ãƒ¢ãƒ‡ãƒ«ï¼ˆ7B/13B/70Bï¼‰ã®SFTãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å®Ÿè¡Œã—ã€å–¶æ¥­è³‡æ–™ç”¨ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã¾ã§ã®å®Œå…¨ãªæ‰‹é †ã‚’èª¬æ˜ã—ã¾ã™ã€‚

### ç›®æ¨™æ€§èƒ½
- **GPUåˆ©ç”¨ç‡**: 90%ä»¥ä¸Š
- **ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°åŠ¹ç‡**: 95%ä»¥ä¸Šï¼ˆ4ãƒãƒ¼ãƒ‰ã¾ã§ï¼‰
- **é€šä¿¡å¸¯åŸŸ**: 920 Gbpsï¼ˆç†è«–å€¤ã®92%ï¼‰

---

## ç’°å¢ƒæ§‹ç¯‰

### 1. äº‹å‰ç¢ºèª

```bash
# ãƒã‚¹ã‚¿ãƒ¼ãƒãƒ¼ãƒ‰ã§å®Ÿè¡Œ
cd /root/test/spectrumx-h200-benchmark

# ãƒãƒ¼ãƒ‰æ¥ç¶šç¢ºèª
pdsh -w "node[001-008]" hostname

# GPUç¢ºèª
pdsh -w "node[001-008]" "nvidia-smi -L" | head -16

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# GPU 0: NVIDIA H200 SXM (UUID: xxx)
# GPU 1: NVIDIA H200 SXM (UUID: xxx)
# ...ï¼ˆå„ãƒãƒ¼ãƒ‰8GPUï¼‰
```

### 2. ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

#### 2.1 åŸºæœ¬ç’°å¢ƒæ§‹ç¯‰

```bash
# ä¸€æ‹¬ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
./setup/install_all.sh

# ã¾ãŸã¯å€‹åˆ¥å®Ÿè¡Œ
./setup/install_dependencies.sh  # ã‚·ã‚¹ãƒ†ãƒ ä¾å­˜é–¢ä¿‚
./setup/install_python_packages.sh  # Pythonç’°å¢ƒ
./setup/configure_nccl.sh  # NCCLæœ€é©åŒ–
```

#### 2.2 NCCLç’°å¢ƒå¤‰æ•°ã®è¨­å®šï¼ˆé‡è¦ï¼‰

```bash
# å…¨ãƒãƒ¼ãƒ‰ã«é…å¸ƒ
cat > /tmp/nccl_env.sh << 'EOF'
# SpectrumX RoCEv2æœ€é©åŒ–è¨­å®š
export NCCL_IB_HCA=mlx5_0,mlx5_1
export NCCL_SOCKET_IFNAME=bond0
export NCCL_IB_GID_INDEX=3
export NCCL_IB_TC=106
export NCCL_IB_QPS_PER_CONNECTION=4
export NCCL_BUFFSIZE=8388608
export NCCL_ALGO=Ring,Tree
export NCCL_COLLNET_ENABLE=0
export NCCL_DEBUG=WARN
EOF

# å„ãƒãƒ¼ãƒ‰ã«ã‚³ãƒ”ãƒ¼
for node in node001 node002 node003 node004 node005 node006 node007 node008; do
    scp /tmp/nccl_env.sh $node:/tmp/
    ssh $node "source /tmp/nccl_env.sh && echo 'source /tmp/nccl_env.sh' >> ~/.bashrc"
done
```

### 3. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«RAIDé…ç½®ï¼‰

```bash
# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
python3 datasets/prepare_custom_dataset.py \
    --model meta-llama/Llama-2-7b-hf \
    --source alpaca \
    --num-samples 50000 \
    --output-dir /raid/datasets/alpaca_tokenized

# å„ãƒãƒ¼ãƒ‰ã®ãƒ­ãƒ¼ã‚«ãƒ«RAIDã«é…å¸ƒ
pdsh -w "node[001-008]" "mkdir -p /raid/datasets"

for node in node001 node002 node003 node004 node005 node006 node007 node008; do
    rsync -avz /raid/datasets/alpaca_tokenized $node:/raid/datasets/
    echo "âœ“ Data copied to $node"
done
```

### 4. Hugging Faceèªè¨¼ï¼ˆLlama-2ä½¿ç”¨æ™‚ï¼‰

```bash
# ãƒˆãƒ¼ã‚¯ãƒ³è¨­å®š
./setup/configure_huggingface.sh

# Llama-2ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ç¢ºèª
python3 -c "
from transformers import AutoConfig
import os
config = AutoConfig.from_pretrained('meta-llama/Llama-2-7b-hf', 
                                    token=os.environ.get('HF_TOKEN'))
print('âœ“ Llama-2 access confirmed')
"
```

---

## ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ

### æ–¹æ³•1: å®Œå…¨è‡ªå‹•å®Ÿè¡Œï¼ˆæ¨å¥¨ï¼‰

```bash
# å…¨ãƒ¢ãƒ‡ãƒ«ãƒ»å…¨ãƒãƒ¼ãƒ‰æ§‹æˆã§è‡ªå‹•å®Ÿè¡Œ
chmod +x scripts/spectrum_x_benchmark.sh
./scripts/spectrum_x_benchmark.sh

# å®Ÿè¡Œå†…å®¹:
# - 2/4/8ãƒãƒ¼ãƒ‰ã§ã®å®Ÿè¡Œ
# - Llama-2 7B/13B/70Bã®3ãƒ¢ãƒ‡ãƒ«
# - è‡ªå‹•ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
# - ãƒ¬ãƒãƒ¼ãƒˆè‡ªå‹•ç”Ÿæˆ
```

### æ–¹æ³•2: å€‹åˆ¥å®Ÿè¡Œ

#### Step 1: NCCLãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ

```bash
# 2ãƒãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ
mpirun -np 16 -H node001,node002 \
    --map-by ppr:8:node \
    /opt/nccl-tests/build/all_reduce_perf \
    -b 256 -e 32G -f 2 -g 1

# æœŸå¾…ã•ã‚Œã‚‹çµæœ:
# 32 GB: ~920 Gbps (ç†è«–å€¤ã®92%)
```

#### Step 2: å˜ä¸€ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

```bash
# Llama-2 7B, 2ãƒãƒ¼ãƒ‰
deepspeed --hostfile hostfile_2nodes \
    --num_nodes 2 \
    --num_gpus 16 \
    scripts/optimized_train.py \
    --model_name_or_path meta-llama/Llama-2-7b-hf \
    --dataset_path /raid/datasets/alpaca_tokenized \
    --output_dir results/7b_2nodes \
    --deepspeed configs/ds_config_7b_optimized.json \
    --max_steps 700 \
    --warmup_steps 200 \
    --bf16 \
    --gradient_checkpointing
```

#### Step 3: GPU/ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

```bash
# åˆ¥ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§å®Ÿè¡Œ

# GPUä½¿ç”¨ç‡ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°
pdsh -w "node[001-002]" \
    "nvidia-smi dmon -s pucvmt -i 0,1,2,3,4,5,6,7" &

# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¸¯åŸŸãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°
pdsh -w "node[001-002]" \
    "sar -n DEV 1 | grep bond0" &
```

### å®Ÿè¡Œæ™‚é–“ã®ç›®å®‰

| ãƒ¢ãƒ‡ãƒ« | ãƒãƒ¼ãƒ‰æ•° | å®Ÿè¡Œæ™‚é–“ |
|--------|---------|----------|
| Llama-2-7B | 2 | ç´„10åˆ† |
| Llama-2-7B | 4 | ç´„8åˆ† |
| Llama-2-7B | 8 | ç´„6åˆ† |
| Llama-2-13B | 4 | ç´„15åˆ† |
| Llama-2-70B | 8 | ç´„30åˆ† |

**ç·å®Ÿè¡Œæ™‚é–“**: å…¨çµ„ã¿åˆã‚ã›ã§ç´„2-3æ™‚é–“

---

## çµæœç¢ºèª

### 1. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼ç¢ºèª

```bash
# æœ€æ–°ã®çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
LATEST_RESULTS=$(ls -td results/spectrumx_benchmark_* | head -1)

# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼è¡¨ç¤º
cat $LATEST_RESULTS/metrics/performance_summary.csv | column -t -s','

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# model_size  nodes  samples_per_sec  gpu_utilization
# 7           2      15234.5          92.3
# 7           4      29876.2          91.8
# 7           8      57234.1          90.5
```

### 2. ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°åŠ¹ç‡ç¢ºèª

```bash
# ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°åˆ†æçµæœ
cat $LATEST_RESULTS/reports/scaling_analysis.json | python3 -m json.tool

# ä¸»è¦æŒ‡æ¨™ã®æŠ½å‡º
python3 << EOF
import json
with open('$LATEST_RESULTS/reports/scaling_analysis.json') as f:
    data = json.load(f)
    for model, results in data.items():
        print(f"\n{model}:")
        for config, metrics in results.items():
            print(f"  {config}: {metrics['efficiency']:.1f}% efficiency")
EOF
```

### 3. å–¶æ¥­è³‡æ–™ã®ç¢ºèª

```bash
# Markdownãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º
cat $LATEST_RESULTS/reports/SpectrumX_H200_Benchmark_Report.md

# HTMLç‰ˆã‚’ç”Ÿæˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
pandoc $LATEST_RESULTS/reports/SpectrumX_H200_Benchmark_Report.md \
    -o $LATEST_RESULTS/reports/report.html \
    --standalone --toc

# PDFã«å¤‰æ›ï¼ˆè¦wkhtmltopdfï¼‰
wkhtmltopdf $LATEST_RESULTS/reports/report.html \
    $LATEST_RESULTS/reports/SpectrumX_H200_Benchmark.pdf
```

---

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### å•é¡Œ1: GPUåˆ©ç”¨ç‡ãŒä½ã„ï¼ˆ<90%ï¼‰

```bash
# åŸå› èª¿æŸ»
nvidia-smi -q -d UTILIZATION | grep -A 5 "GPU Utilization"

# è§£æ±ºç­–
# 1. ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å¢—ã‚„ã™
sed -i 's/"train_micro_batch_size_per_gpu": 8/"train_micro_batch_size_per_gpu": 16/' \
    configs/ds_config_7b_optimized.json

# 2. Gradient Accumulation ã‚’æ¸›ã‚‰ã™
sed -i 's/"gradient_accumulation_steps": 16/"gradient_accumulation_steps": 8/' \
    configs/ds_config_7b_optimized.json
```

### å•é¡Œ2: NCCLé€šä¿¡ã‚¨ãƒ©ãƒ¼

```bash
# ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰æœ‰åŠ¹åŒ–
export NCCL_DEBUG=INFO
export NCCL_DEBUG_SUBSYS=ALL

# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç¢ºèª
pdsh -w "node[001-008]" "ibstatus" | grep -E "state|rate"
pdsh -w "node[001-008]" "ip link show bond0"

# RoCEv2è¨­å®šç¢ºèª
pdsh -w "node[001-008]" "cma_roce_mode -d mlx5_0"
```

### å•é¡Œ3: Out of Memory

```bash
# 70Bãƒ¢ãƒ‡ãƒ«ç”¨ã®èª¿æ•´
# CPU Offloadã‚’æœ‰åŠ¹åŒ–
sed -i 's/"device": "none"/"device": "cpu"/' \
    configs/ds_config_70b_optimized.json

# Activation Checkpointingã®èª¿æ•´
sed -i 's/"number_checkpoints": null/"number_checkpoints": 4/' \
    configs/ds_config_70b_optimized.json
```

### å•é¡Œ4: ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°åŠ¹ç‡ãŒä½ã„

```bash
# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æœ€é©åŒ–ã®å†ç¢ºèª
# 1. Multi-railè¨­å®š
export NCCL_IB_HCA=mlx5_0,mlx5_1

# 2. QoSè¨­å®š
sudo mlnx_qos -i mlx5_0 --trust dscp
sudo mlnx_qos -i mlx5_1 --trust dscp

# 3. ECNæœ‰åŠ¹åŒ–
echo 1 | sudo tee /sys/class/net/mlx5_0/ecn/enable
echo 1 | sudo tee /sys/class/net/mlx5_1/ecn/enable
```

---

## ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã¾ã¨ã‚

### âœ… å¿…é ˆè¨­å®š

1. **NCCLç’°å¢ƒå¤‰æ•°**: å¿…ãšè¨­å®šã™ã‚‹
2. **ãƒ­ãƒ¼ã‚«ãƒ«RAID**: NFSã¯ä½¿ã‚ãªã„
3. **BF16ç²¾åº¦**: H200ã§ã¯å¿…é ˆ
4. **Flash Attention 2**: æœ‰åŠ¹åŒ–å¿…é ˆ

### ğŸ“Š æ¨å¥¨æ§‹æˆ

| ãƒ¢ãƒ‡ãƒ« | ãƒãƒ¼ãƒ‰æ•° | ãƒãƒƒãƒã‚µã‚¤ã‚º | Gradient Accumulation |
|--------|---------|--------------|---------------------|
| 7B | 2-4 | 8-16 | 16 |
| 13B | 4 | 4-8 | 16 |
| 70B | 8 | 1-2 | 32 |

### ğŸ¯ æœŸå¾…ã•ã‚Œã‚‹çµæœ

- **GPUåˆ©ç”¨ç‡**: 92-95%
- **ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°åŠ¹ç‡**: 
  - 2â†’4ãƒãƒ¼ãƒ‰: 96%
  - 4â†’8ãƒãƒ¼ãƒ‰: 93%
- **é€šä¿¡å¸¯åŸŸ**: 920 Gbpsï¼ˆãƒ”ãƒ¼ã‚¯ï¼‰

---

## ã‚µãƒãƒ¼ãƒˆ

æŠ€è¡“çš„ãªå•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆã¯ã€ä»¥ä¸‹ã®æƒ…å ±ã‚’å«ã‚ã¦ãŠå•ã„åˆã‚ã›ãã ã•ã„ï¼š

1. å®Ÿè¡Œãƒ­ã‚°: `results/*/benchmark.log`
2. GPUçŠ¶æ…‹: `nvidia-smi -q`ã®å‡ºåŠ›
3. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çŠ¶æ…‹: `ibstatus`ã®å‡ºåŠ›
4. NCCLè¨­å®š: `env | grep NCCL`ã®å‡ºåŠ›

---

*æœ€çµ‚æ›´æ–°: 2025å¹´8æœˆ*