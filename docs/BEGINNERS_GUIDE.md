# 🎓 マルチノード分散学習 初心者ガイド

このガイドは、マルチノード分散学習を初めて扱う方向けに作成されています。

## 📚 基本概念の理解

### マルチノード分散学習とは？
複数のコンピュータ（ノード）を使って、大規模な機械学習モデルを効率的に訓練する技術です。

#### なぜ必要？
- **大規模モデル**: 1台のGPUに収まらないモデルも訓練可能
- **高速化**: 複数GPUで並列処理により訓練時間を短縮
- **スケーラビリティ**: ノードを追加して性能向上

### 重要な用語
- **ノード**: 1台のコンピュータ（サーバー）
- **GPU**: グラフィックス処理装置（AIの計算に使用）
- **SSH**: ノード間の安全な通信プロトコル
- **PDSH**: 複数ノードに同時にコマンドを実行するツール
- **DeepSpeed**: 分散学習を効率化するライブラリ

## 🔧 事前準備チェックリスト

### 1. SSH接続の基礎
```bash
# 通常のSSH接続（このプロジェクトは違います）
ssh username@hostname

# このプロジェクトのSSH接続（ポート44222を使用）
ssh -p 44222 username@hostname
```

### 2. 必要な知識
- [ ] 基本的なLinuxコマンド（cd, ls, cat など）
- [ ] Pythonの基礎知識
- [ ] 機械学習の基本概念

## 🚀 ステップバイステップガイド

### Step 1: 接続確認（5分）
```bash
# まず自分がどのノードにいるか確認
hostname

# 他のノードに接続できるか確認
ssh -p 44222 fukushimadc-02-hgx-0002 hostname
# 成功すれば "fukushimadc-02-hgx-0002" と表示されます
```

### Step 2: プロジェクトの準備（10分）
```bash
# プロジェクトディレクトリに移動
cd /root/test/spectrumx-h200-benchmark

# 簡単な動作確認
./test_quick.sh
```

期待される出力:
```
=== SpectrumX H200 Cluster Quick Test ===
✓ SSH connectivity to nodes
✓ GPU detection
✓ Basic requirements
```

### Step 3: 自動セットアップ（30-60分）
```bash
# 全自動セットアップ（コーヒーでも飲みながら待ちましょう）
./run_all.sh setup
```

このコマンドが行うこと:
1. 必要なソフトウェアのインストール
2. Python環境の構築
3. ネットワーク設定の最適化
4. 全ノードの設定同期

### Step 4: 最初のマルチノードテスト（5分）
```bash
# 2ノードで簡単なテストを実行
./run_all.sh bench meta-llama/Llama-2-7b-hf 2 nccl
```

これは何をしているの？
- 2台のノードを使用
- 7Bパラメータのモデル
- 通信性能のテストのみ（学習はまだ）

### Step 5: 実際の分散学習（15-30分）
```bash
# 2ノードでSFT（教師あり微調整）を実行
./run_all.sh bench meta-llama/Llama-2-7b-hf 2 sft
```

## 📊 結果の見方

### 成功の確認
```bash
# レポートを生成
./run_all.sh report

# 結果を確認
cat docs/benchmark_report.md
```

注目すべき指標:
- **GPU利用率**: 80%以上なら良好
- **スループット**: samples/secondの値
- **スケーリング効率**: 90%以上が理想

### よくあるエラーと対処法

#### 1. SSH接続エラー
```
ssh: connect to host xxx port 44222: Connection refused
```
対処: ノードが起動しているか、ポート番号が正しいか確認

#### 2. GPU認識エラー
```
No GPUs found
```
対処: `nvidia-smi`コマンドで確認、ドライバの問題の可能性

#### 3. メモリ不足
```
CUDA out of memory
```
対処: バッチサイズを小さくする（設定ファイルで調整）

## 🎯 次のステップ

### 初級者向け課題
1. 3ノードでのテストを実行してみる
2. 異なるモデルサイズ（13B）を試す
3. メトリクスの変化を観察する

### 中級者向け課題
1. DeepSpeed設定をカスタマイズ
2. 独自のデータセットを使用
3. 性能チューニング

## 💡 ヒントとコツ

### パフォーマンスを向上させるには
1. **ノード数とバッチサイズのバランス**
   - ノード数を増やしたらバッチサイズも調整
   
2. **通信の最適化**
   - NCCLテストで通信性能を確認
   - ネットワークがボトルネックになっていないか確認

3. **モニタリング**
   - `watch nvidia-smi`でGPU使用率を監視
   - ログファイルで進行状況を確認

### トラブルシューティングのコツ
1. **まず小規模でテスト**
   - 1ノード → 2ノード → 4ノードと段階的に

2. **ログを必ず確認**
   ```bash
   # 最新のログを確認
   ls -la results/*/
   tail -f results/latest/benchmark.log
   ```

3. **環境変数の確認**
   ```bash
   # 設定されている環境変数を確認
   printenv | grep -E "NCCL|CUDA|HF"
   ```

## 📚 さらに学ぶには

### 推奨リソース
1. **DeepSpeedドキュメント**: 分散学習の詳細
2. **NCCLガイド**: GPU間通信の最適化
3. **PyTorch分散学習チュートリアル**: 基本概念の理解

### このプロジェクトのドキュメント
- `README.md`: 全体概要
- `CLAUDE.md`: 技術仕様
- `PROJECT_STATUS.md`: 現在の状態
- `docs/SFT_TRAINING_GUIDE.md`: SFT訓練の詳細

## 🤝 困ったときは

1. **エラーメッセージをよく読む**
   - 多くの場合、解決のヒントが含まれています

2. **小さく始める**
   - いきなり8ノードではなく、2ノードから

3. **ログを保存**
   - 問題が起きたときのために、実行ログを保存

---

おめでとうございます！これでマルチノード分散学習の第一歩を踏み出しました。
少しずつ理解を深めながら、より大規模な実験に挑戦してください！